# -*- coding: utf-8 -*-
"""LVADSUSR98-Marimuthu P-FA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kQi-keFEQYC-AtAk5oJmAqw7z-DcjaQ4
"""

#Q1
import pandas as pd
df = pd.read_csv("/content/Walmart_Dataset Python_Final_Assessment.csv")
print(df.info())
print(df.describe())

#Q2
print(df[df.duplicated()])
print(df.count())
df.dropna()
df.count()

#Q3
print("Mean: Sales \n", df['Sales'].mean())
print("Median: Sales \n", df['Sales'].median())
print("Mode: Sales \n", df['Sales'].mode())
print("Range: Sales \n", df['Sales'].max() - df['Sales'].min())
print("Variance: Sales \n", df['Sales'].var())
print("Standard Deviation: Sales \n", df['Sales'].std())
print("Mean: Quantity \n", df['Quantity'].mean())
print("Median: Quantity \n", df['Quantity'].median())
print("Mode: Quantity \n", df['Quantity'].mode())
print("Range: Quantity \n", df['Quantity'].max() - df['Quantity'].min())
print("Variance: Quantity \n", df['Quantity'].var())
print("Standard Deviation: Quantity \n", df['Quantity'].std())
print("Mean: Profit \n", df['Profit'].mean())
print("Median: Profit \n", df['Profit'].median())
print("Mode: Profit \n", df['Profit'].mode())
print("Range: Profit \n", df['Profit'].max() - df['Profit'].min())
print("Variance: Profit \n", df['Profit'].var())
print("Standard Profit: Profit \n", df['Profit'].std())

## 4
walmartdata=pd.read_csv("/content/Walmart_Dataset Python_Final_Assessment.csv")

class walmart_analysis:
  def __init__(self,walmartdata):
    self.df=walmartdata
  def category_profit_analysis(self):
    category=df.groupby(self.df["Category"]).aggregate({"Profit":"sum"})
    sns.barplot(y="Category",x="Profit",data=category)
  def category_sales_analysis(self):
    category=df.groupby(self.df["Category"]).aggregate({"Sales":"sum"})
    sns.barplot(y="Category",x="Sales",data=category)
  def year_wise_profit(self):
    self.df["Ship Date"]=pd.to_datetime(self.df["Ship Date"])
    self.df["year"]=self.df["Ship Date"].dt.year
    year=df.groupby(self.df["year"]).aggregate({"Profit":"sum"})
    sns.barplot(x="year",y="Profit",data=year)
  def year_wise_Sales(self):
    self.df["Ship Date"]=pd.to_datetime(self.df["Ship Date"])
    self.df["year"]=self.df["Ship Date"].dt.year
    year=df.groupby(self.df["year"]).aggregate({"Sales":"sum"})
    sns.barplot(x="year",y="Sales",data=year)
  def category_analysis(self):
    category=df.groupby(self.df["Category"]).aggregate({"Profit":"sum","Sales":"sum"})
    fig,axes=plt.subplots(1,2)
    sns.lineplot(x="Category",y="Profit",data=category,ax=axes[0])
    sns.lineplot(x="Category",y="Sales",data=category,ax=axes[1])
  def category_wise_quantity_heatmap(self):

    category=self.df.pivot_table(index="Category",values="Quantity",aggfunc="sum")
    sns.heatmap(category,annot=True)




obj=walmart_analysis(walmartdata)
obj.category_wise_quantity_heatmap()

## category wise profit visualization
obj=walmart_analysis(walmartdata)
obj.category_profit_analysis()

## category wise sales visualization
obj=walmart_analysis(walmartdata)
obj.category_sales_analysis()

##category wise analysis with quantity in heatmap
obj=walmart_analysis(walmartdata)
obj.category_wise_quantity_heatmap()

## year wise profit visualization
obj=walmart_analysis(walmartdata)

obj.year_wise_profit()

## year wise sales visualization
obj=walmart_analysis(walmartdata)
obj.year_wise_Sales()

## category sales and profit
obj=walmart_analysis(walmartdata)
obj.category_analysis()

## 5
## correlation between quantity and profit for each category
df=pd.read_csv("/content/Walmart_Dataset Python_Final_Assessment.csv")
df1=df.groupby("Category").aggregate({"Quantity":"sum","Profit":"sum"})
print(df1.corr())
sns.heatmap(df1.corr(),annot=True)
plt.show()
## here in the output we can see that the both quantity and profit are partialy corelatted which means that they are not competely dependent
## but they are dependent

## correlation between sales and profit for each category
df=pd.read_csv("/content/Walmart_Dataset Python_Final_Assessment.csv")
df1=df.groupby("Category").aggregate({"Sales":"sum","Profit":"sum"})
print(df1.corr())
sns.heatmap(df1.corr(),annot=True)
plt.show()
## based on this output sales and profit are not mostly dependent on each other

## correlation between countries and order count for each category
df=pd.read_csv("/content/Walmart_Dataset Python_Final_Assessment.csv")
df1=df.groupby("Geography").aggregate({"Order ID":"count","Quantity":"sum"})
print(df1.corr())
sns.heatmap(df1.corr(),annot=True)
plt.show()
## here from this output you can see that the count of order id is completely dependent on quantity

#6
numeric_cols = ['Sales', 'Quantity', 'Profit']
df_zscores = df[numeric_cols].apply(lambda x: np.abs((x - x.mean()) / x.std()))

outliers = df_zscores > 3

outliers_data = df[outliers.any(axis=1)]

print("Outliers:")
print(outliers_data)

plt.figure(figsize=(10, 6))
sns.boxplot(data=df[numeric_cols])
plt.title('Boxplot of Sales, Quantity, and Profit')
plt.xlabel('Features')
plt.ylabel('Values')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#Q7 - Trend Analysis
# i)
df['Order Month'] = pd.to_datetime(df['Order Date']).dt.month
salesData = df.groupby('Order Year')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Year')['Profit'].sum()
profitData.plot(label='Profit')
plt.grid(True)
plt.legend()
plt.show()

salesData = df.groupby('Order Month')['Sales'].sum()
salesData.plot(label='Sales')
profitData = df.groupby('Order Month')['Profit'].sum()
profitData.plot(label='Profit')
plt.grid(True)
plt.legend()
plt.show()

# ii)
total_sales = df.groupby(['Order Year', 'Category'])['Sales'].sum().reset_index()
total_sales['Growth'] = total_sales.groupby('Category')['Sales'].pct_change() * 100
most_growth_category = total_sales.groupby('Category')['Growth'].mean().idxmax()
print("Category with the Most Growth in Sales:", most_growth_category)

#Q7- Customer Analysis
#i)
customer_summary = df.groupby('EmailID').agg({'Order ID': 'nunique', 'Sales': 'sum'}).reset_index()
customer_summary.columns = ['EmailID', 'Quantity', 'TotalSales']

top_customers_by_orders = customer_summary.nlargest(5, 'Quantity')
top_customers_by_sales = customer_summary.nlargest(5, 'TotalSales')

print("Top 5 Customers by Orders Placed:")
print(top_customers_by_orders.set_index('EmailID'))
print("\nTop 5 Customers by Total Sales:")
print(top_customers_by_sales.set_index('EmailID'))

#Q7- Customer Analysis
#ii)
df['OrderDate'] = pd.to_datetime(df['Order Date'])
df.sort_values(by=['EmailID', 'Order Date'], inplace=True)
df['TimeBetweenOrders'] = df.groupby('EmailID')['Order Date'].diff()
average_time_between_orders = df.groupby('EmailID')['TimeBetweenOrders'].mean()

print("Average Time Between Orders for Each Customer:")
print(average_time_between_orders)
print(average_time_between_orders.mean())

"""#Comprehensive Analysis"""

#average Time between order and delivery
df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('Category')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery)

df['TimeBetweenOrderAndDelivery'] = df['Ship Date'] - df['Order Date']
average_time_between_order_and_delivery = df.groupby('EmailID')['TimeBetweenOrderAndDelivery'].mean()
print(average_time_between_order_and_delivery.mean())

#### i)

import plotly.express as px
fig = px.scatter_geo(df, locations="Geography", locationmode="USA-states",
                      hover_name="Product Name", size="Sales", color="Sales",
                      scope="usa", title="Geographical Distribution")
fig.show()
#Places cannot be plotted because of lack of lat long.

#### ii)

customer_order_amounts = df.groupby('EmailID')['Sales'].sum().reset_index()

top_10_percent = int(len(customer_order_amounts) * 0.1)
high_value_customers = customer_order_amounts.nlargest(top_10_percent, 'Sales')
print("High value Customers based on purchase Value:")
print(high_value_customers)

customer_order_amounts = df.groupby('EmailID')['Quantity'].sum().reset_index()

top_10_percent = int(len(customer_order_amounts) * 0.1)
high_value_customers = customer_order_amounts.nlargest(top_10_percent, 'Quantity')
print("High value Customers based on purchase Quantity:")
print(high_value_customers)

df.sort_values(by=['EmailID', 'Order Date'], inplace=True)
df['TimeBetweenOrders'] = df.groupby('EmailID')['Order Date'].diff()
average_time_between_orders = df.groupby('EmailID')['TimeBetweenOrders'].mean()
print("High value Customers based on purchase Frequency:")
print(average_time_between_orders.nsmallest(top_10_percent))

for index, customer in high_value_customers.iterrows():
  pass
  #We can write a function to send promotional offers to these value customers

"""### iii) High value customers can be identified by their purchasing quantity, purchase frequency and pruchase amount .
 These customers can be given additional promotions and offers to enhance customer loyalty and they are more likely to recommend wallmart to other potential customers"""